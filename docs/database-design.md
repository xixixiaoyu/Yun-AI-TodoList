# æ•°æ®åº“è®¾è®¡æ–¹æ¡ˆï¼šé«˜æ€§èƒ½æ•°æ®æ¶æ„

## æŠ€æœ¯æ¦‚è¿°

æœ¬é¡¹ç›®é‡‡ç”¨ PostgreSQL + Prisma ORM +
Redis ç¼“å­˜çš„æ•°æ®æ¶æ„ï¼Œå®ç°äº†é«˜æ€§èƒ½ã€é«˜å¯ç”¨çš„æ•°æ®å­˜å‚¨æ–¹æ¡ˆï¼Œæ”¯æŒå¤æ‚æŸ¥è¯¢ã€äº‹åŠ¡å¤„ç†ã€æ•°æ®ç¼“å­˜å’Œå®æ—¶åŒæ­¥ã€‚

## ğŸ—„ï¸ æ•°æ®åº“æ¶æ„è®¾è®¡

### æ ¸å¿ƒæŠ€æœ¯æ ˆ

- **PostgreSQL 15+**ï¼šä¸»æ•°æ®åº“ï¼Œæ”¯æŒ JSONBã€å…¨æ–‡æœç´¢ã€åˆ†åŒºè¡¨
- **Prisma ORM**ï¼šç±»å‹å®‰å…¨çš„æ•°æ®åº“è®¿é—®å±‚
- **Redis 7+**ï¼šç¼“å­˜å±‚ï¼Œæ”¯æŒæ•°æ®ç»“æ„ã€å‘å¸ƒè®¢é˜…
- **è¿æ¥æ± **ï¼šPgBouncer è¿æ¥æ± ç®¡ç†

### æ•°æ®åº“ Schema è®¾è®¡

```prisma
// schema.prisma
generator client {
  provider = "prisma-client-js"
  previewFeatures = ["fullTextSearch", "postgresqlExtensions"]
}

datasource db {
  provider = "postgresql"
  url      = env("DATABASE_URL")
  extensions = [uuid_ossp, pg_trgm, btree_gin]
}

// ç”¨æˆ·è¡¨
model User {
  id        String   @id @default(dbgenerated("uuid_generate_v4()")) @db.Uuid
  email     String   @unique @db.VarChar(255)
  password  String   @db.VarChar(255)
  name      String   @db.VarChar(100)
  avatar    String?  @db.Text
  role      Role     @default(USER)

  // ç”¨æˆ·åå¥½è®¾ç½®
  preferences Json @default("{}") @db.JsonB

  // å®‰å…¨ç›¸å…³
  emailVerified      Boolean   @default(false)
  emailVerifiedAt    DateTime?
  passwordChangedAt  DateTime?
  lastLoginAt        DateTime?
  lastLoginIp        String?   @db.Inet
  lastLoginUserAgent String?   @db.Text
  isActive           Boolean   @default(true)
  forcePasswordChange Boolean  @default(false)

  // æ³¨å†Œä¿¡æ¯
  registrationIp        String?  @db.Inet
  registrationUserAgent String?  @db.Text

  // æ—¶é—´æˆ³
  createdAt DateTime @default(now())
  updatedAt DateTime @updatedAt

  // å…³è”å…³ç³»
  todos         Todo[]
  searchHistory SearchHistory[]
  userSettings  UserSettings?
  todoHistory   TodoHistory[]
  aiUsageStats  AIUsageStats[]
  securityLogs  SecurityLog[]

  // ç´¢å¼•
  @@index([email])
  @@index([lastLoginAt])
  @@index([createdAt])
  @@map("users")
}

// è§’è‰²æšä¸¾
enum Role {
  ADMIN
  USER
  MODERATOR

  @@map("role")
}

// å¾…åŠäº‹é¡¹è¡¨
model Todo {
  id          String   @id @default(dbgenerated("uuid_generate_v4()")) @db.Uuid
  title       String   @db.VarChar(200)
  description String?  @db.Text
  completed   Boolean  @default(false)
  priority    Priority @default(MEDIUM)

  // æ—¶é—´ç®¡ç†
  estimatedTime Int?     // é¢„ä¼°æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰
  actualTime    Int?     // å®é™…æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰
  dueDate       DateTime?
  completedAt   DateTime?

  // AI ç›¸å…³
  aiAnalyzed    Boolean @default(false)
  aiSuggestions Json?   @db.JsonB
  aiTags        String[] @db.VarChar(50)

  // åˆ†ç±»å’Œæ ‡ç­¾
  category String?   @db.VarChar(50)
  tags     String[] @db.VarChar(50)

  // é™„ä»¶å’Œé“¾æ¥
  attachments Json? @db.JsonB
  links       Json? @db.JsonB

  // ä½ç½®ä¿¡æ¯
  location Json? @db.JsonB

  // æ—¶é—´æˆ³
  createdAt DateTime @default(now())
  updatedAt DateTime @updatedAt

  // å…³è”å…³ç³»
  userId      String       @db.Uuid
  user        User         @relation(fields: [userId], references: [id], onDelete: Cascade)
  todoHistory TodoHistory[]

  // å…¨æ–‡æœç´¢
  @@index([title, description], type: Gin)
  @@index([userId, completed])
  @@index([userId, priority])
  @@index([userId, dueDate])
  @@index([userId, createdAt])
  @@index([aiTags], type: Gin)
  @@index([tags], type: Gin)
  @@map("todos")
}

// ä¼˜å…ˆçº§æšä¸¾
enum Priority {
  LOW
  MEDIUM
  HIGH
  URGENT

  @@map("priority")
}

// ç”¨æˆ·è®¾ç½®è¡¨
model UserSettings {
  id     String @id @default(dbgenerated("uuid_generate_v4()")) @db.Uuid
  userId String @unique @db.Uuid

  // ä¸»é¢˜è®¾ç½®
  theme          String  @default("light") @db.VarChar(20)
  language       String  @default("zh-CN") @db.VarChar(10)
  timezone       String  @default("Asia/Shanghai") @db.VarChar(50)
  dateFormat     String  @default("YYYY-MM-DD") @db.VarChar(20)
  timeFormat     String  @default("HH:mm") @db.VarChar(10)

  // AI è®¾ç½®
  aiEnabled      Boolean @default(true)
  aiModel        String  @default("deepseek-chat") @db.VarChar(50)
  aiApiKey       String? @db.Text // åŠ å¯†å­˜å‚¨
  aiSystemPrompt String? @db.Text

  // æœç´¢è®¾ç½®
  searchEnabled     Boolean @default(true)
  searchEngine      String  @default("google") @db.VarChar(20)
  searchApiKey      String? @db.Text // åŠ å¯†å­˜å‚¨
  searchResultLimit Int     @default(10)

  // é€šçŸ¥è®¾ç½®
  notifications Json @default("{}") @db.JsonB

  // éšç§è®¾ç½®
  dataRetention Json @default("{}") @db.JsonB

  // æ—¶é—´æˆ³
  createdAt DateTime @default(now())
  updatedAt DateTime @updatedAt

  // å…³è”å…³ç³»
  user User @relation(fields: [userId], references: [id], onDelete: Cascade)

  @@map("user_settings")
}

// æœç´¢å†å²è¡¨
model SearchHistory {
  id       String @id @default(dbgenerated("uuid_generate_v4()")) @db.Uuid
  userId   String @db.Uuid
  query    String @db.VarChar(500)
  results  Json?  @db.JsonB
  source   String @db.VarChar(20) // 'ai' | 'google' | 'local'

  // ç»Ÿè®¡ä¿¡æ¯
  resultCount Int @default(0)
  clickCount  Int @default(0)

  // æ—¶é—´æˆ³
  createdAt DateTime @default(now())

  // å…³è”å…³ç³»
  user User @relation(fields: [userId], references: [id], onDelete: Cascade)

  // ç´¢å¼•
  @@index([userId, createdAt])
  @@index([query], type: Gin)
  @@map("search_history")
}

// å¾…åŠå†å²è¡¨ï¼ˆç”¨äºç‰ˆæœ¬æ§åˆ¶å’Œå®¡è®¡ï¼‰
model TodoHistory {
  id       String @id @default(dbgenerated("uuid_generate_v4()")) @db.Uuid
  todoId   String @db.Uuid
  userId   String @db.Uuid
  action   String @db.VarChar(20) // 'created', 'updated', 'deleted', 'completed'

  // å˜æ›´å‰åçš„æ•°æ®
  oldData Json? @db.JsonB
  newData Json? @db.JsonB
  changes Json? @db.JsonB // å…·ä½“å˜æ›´å­—æ®µ

  // æ“ä½œä¿¡æ¯
  ip        String? @db.Inet
  userAgent String? @db.Text

  // æ—¶é—´æˆ³
  createdAt DateTime @default(now())

  // å…³è”å…³ç³»
  todo Todo @relation(fields: [todoId], references: [id], onDelete: Cascade)
  user User @relation(fields: [userId], references: [id], onDelete: Cascade)

  // ç´¢å¼•
  @@index([todoId, createdAt])
  @@index([userId, createdAt])
  @@index([action])
  @@map("todo_history")
}

// AI ä½¿ç”¨ç»Ÿè®¡è¡¨
model AIUsageStats {
  id     String @id @default(dbgenerated("uuid_generate_v4()")) @db.Uuid
  userId String @db.Uuid

  // ä½¿ç”¨ç»Ÿè®¡
  requestCount    Int @default(0)
  tokenUsed       Int @default(0)
  successCount    Int @default(0)
  errorCount      Int @default(0)

  // åŠŸèƒ½ä½¿ç”¨ç»Ÿè®¡
  chatUsage        Int @default(0)
  suggestionUsage  Int @default(0)
  analysisUsage    Int @default(0)

  // æˆæœ¬ç»Ÿè®¡
  estimatedCost Float @default(0.0) @db.DoublePrecision

  // ç»Ÿè®¡å‘¨æœŸ
  date DateTime @db.Date

  // æ—¶é—´æˆ³
  createdAt DateTime @default(now())
  updatedAt DateTime @updatedAt

  // å…³è”å…³ç³»
  user User @relation(fields: [userId], references: [id], onDelete: Cascade)

  // å”¯ä¸€çº¦æŸ
  @@unique([userId, date])
  @@index([date])
  @@map("ai_usage_stats")
}

// å®‰å…¨æ—¥å¿—è¡¨
model SecurityLog {
  id     String @id @default(dbgenerated("uuid_generate_v4()")) @db.Uuid
  userId String? @db.Uuid

  // äº‹ä»¶ä¿¡æ¯
  eventType String @db.VarChar(50)
  severity  String @db.VarChar(20) // 'low', 'medium', 'high', 'critical'
  message   String @db.Text
  details   Json?  @db.JsonB

  // è¯·æ±‚ä¿¡æ¯
  ip        String? @db.Inet
  userAgent String? @db.Text
  endpoint  String? @db.VarChar(200)
  method    String? @db.VarChar(10)

  // çŠ¶æ€
  resolved   Boolean   @default(false)
  resolvedAt DateTime?
  resolvedBy String?   @db.Uuid

  // æ—¶é—´æˆ³
  createdAt DateTime @default(now())

  // å…³è”å…³ç³»
  user User? @relation(fields: [userId], references: [id], onDelete: SetNull)

  // ç´¢å¼•
  @@index([eventType, createdAt])
  @@index([severity, resolved])
  @@index([ip, createdAt])
  @@index([userId, createdAt])
  @@map("security_logs")
}

// ç³»ç»Ÿé…ç½®è¡¨
model SystemConfig {
  id    String @id @default(dbgenerated("uuid_generate_v4()")) @db.Uuid
  key   String @unique @db.VarChar(100)
  value Json   @db.JsonB

  // é…ç½®å…ƒä¿¡æ¯
  description String?  @db.Text
  category    String?  @db.VarChar(50)
  isPublic    Boolean  @default(false)
  isEditable  Boolean  @default(true)

  // æ—¶é—´æˆ³
  createdAt DateTime @default(now())
  updatedAt DateTime @updatedAt

  @@index([category])
  @@map("system_config")
}
```

## ğŸš€ æ•°æ®åº“ä¼˜åŒ–ç­–ç•¥

### ç´¢å¼•ä¼˜åŒ–

```sql
-- å¤åˆç´¢å¼•ä¼˜åŒ–
CREATE INDEX CONCURRENTLY idx_todos_user_status_priority
ON todos (user_id, completed, priority, created_at DESC);

-- éƒ¨åˆ†ç´¢å¼•ï¼ˆåªç´¢å¼•æœªå®Œæˆçš„å¾…åŠï¼‰
CREATE INDEX CONCURRENTLY idx_todos_incomplete
ON todos (user_id, due_date)
WHERE completed = false;

-- è¡¨è¾¾å¼ç´¢å¼•ï¼ˆç”¨äºæœç´¢ï¼‰
CREATE INDEX CONCURRENTLY idx_todos_search
ON todos USING gin(to_tsvector('english', title || ' ' || COALESCE(description, '')));

-- JSONB ç´¢å¼•
CREATE INDEX CONCURRENTLY idx_user_preferences
ON users USING gin(preferences);

-- æ•°ç»„ç´¢å¼•
CREATE INDEX CONCURRENTLY idx_todos_tags
ON todos USING gin(tags);
```

### åˆ†åŒºè¡¨è®¾è®¡

```sql
-- æŒ‰æ—¶é—´åˆ†åŒºçš„æ—¥å¿—è¡¨
CREATE TABLE security_logs_partitioned (
  LIKE security_logs INCLUDING ALL
) PARTITION BY RANGE (created_at);

-- åˆ›å»ºæœˆåº¦åˆ†åŒº
CREATE TABLE security_logs_2024_01 PARTITION OF security_logs_partitioned
FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');

CREATE TABLE security_logs_2024_02 PARTITION OF security_logs_partitioned
FOR VALUES FROM ('2024-02-01') TO ('2024-03-01');

-- è‡ªåŠ¨åˆ†åŒºç®¡ç†å‡½æ•°
CREATE OR REPLACE FUNCTION create_monthly_partition(table_name text, start_date date)
RETURNS void AS $$
DECLARE
  partition_name text;
  end_date date;
BEGIN
  partition_name := table_name || '_' || to_char(start_date, 'YYYY_MM');
  end_date := start_date + interval '1 month';

  EXECUTE format('CREATE TABLE IF NOT EXISTS %I PARTITION OF %I
                  FOR VALUES FROM (%L) TO (%L)',
                 partition_name, table_name, start_date, end_date);
END;
$$ LANGUAGE plpgsql;
```

### æŸ¥è¯¢ä¼˜åŒ–

```typescript
// apps/backend/src/database/database.service.ts
import { Injectable, OnModuleInit } from '@nestjs/common'
import { PrismaClient } from '@prisma/client'
import { ConfigService } from '@nestjs/config'

@Injectable()
export class DatabaseService extends PrismaClient implements OnModuleInit {
  constructor(private configService: ConfigService) {
    super({
      datasources: {
        db: {
          url: configService.get('DATABASE_URL'),
        },
      },
      log: [
        { level: 'query', emit: 'event' },
        { level: 'error', emit: 'event' },
        { level: 'info', emit: 'event' },
        { level: 'warn', emit: 'event' },
      ],
      errorFormat: 'pretty',
    })

    // æŸ¥è¯¢æ—¥å¿—è®°å½•
    this.$on('query', (e) => {
      if (e.duration > 1000) {
        // è®°å½•æ…¢æŸ¥è¯¢
        console.warn(`Slow query detected: ${e.duration}ms`, {
          query: e.query,
          params: e.params,
        })
      }
    })
  }

  async onModuleInit() {
    await this.$connect()

    // æ•°æ®åº“è¿æ¥æ± é…ç½®
    await this.$executeRaw`SET statement_timeout = '30s'`
    await this.$executeRaw`SET lock_timeout = '10s'`
    await this.$executeRaw`SET idle_in_transaction_session_timeout = '60s'`
  }

  // æ‰¹é‡æ“ä½œä¼˜åŒ–
  async batchCreateTodos(todos: any[], userId: string) {
    return this.$transaction(async (tx) => {
      const results = []

      // åˆ†æ‰¹å¤„ç†ï¼Œé¿å…å•æ¬¡äº‹åŠ¡è¿‡å¤§
      const batchSize = 100
      for (let i = 0; i < todos.length; i += batchSize) {
        const batch = todos.slice(i, i + batchSize)
        const batchResults = await tx.todo.createMany({
          data: batch.map((todo) => ({ ...todo, userId })),
          skipDuplicates: true,
        })
        results.push(batchResults)
      }

      return results
    })
  }

  // å¤æ‚æŸ¥è¯¢ä¼˜åŒ–
  async getTodoStatistics(
    userId: string,
    dateRange?: { start: Date; end: Date }
  ) {
    const whereClause = {
      userId,
      ...(dateRange && {
        createdAt: {
          gte: dateRange.start,
          lte: dateRange.end,
        },
      }),
    }

    // ä½¿ç”¨åŸç”Ÿ SQL è¿›è¡Œå¤æ‚ç»Ÿè®¡
    const stats = await this.$queryRaw`
      SELECT 
        COUNT(*) as total,
        COUNT(*) FILTER (WHERE completed = true) as completed,
        COUNT(*) FILTER (WHERE priority = 'HIGH') as high_priority,
        COUNT(*) FILTER (WHERE priority = 'URGENT') as urgent,
        AVG(CASE WHEN completed = true AND actual_time IS NOT NULL 
            THEN actual_time END) as avg_completion_time,
        COUNT(DISTINCT category) as categories_count
      FROM todos 
      WHERE user_id = ${userId}
        ${dateRange ? Prisma.sql`AND created_at BETWEEN ${dateRange.start} AND ${dateRange.end}` : Prisma.empty}
    `

    return stats[0]
  }

  // å…¨æ–‡æœç´¢ä¼˜åŒ–
  async searchTodos(
    userId: string,
    query: string,
    options: {
      limit?: number
      offset?: number
      filters?: any
    } = {}
  ) {
    const { limit = 20, offset = 0, filters = {} } = options

    return this.$queryRaw`
      SELECT 
        *,
        ts_rank(to_tsvector('english', title || ' ' || COALESCE(description, '')), 
                plainto_tsquery('english', ${query})) as rank
      FROM todos
      WHERE user_id = ${userId}
        AND to_tsvector('english', title || ' ' || COALESCE(description, '')) 
            @@ plainto_tsquery('english', ${query})
        ${
          filters.completed !== undefined
            ? Prisma.sql`AND completed = ${filters.completed}`
            : Prisma.empty
        }
        ${
          filters.priority
            ? Prisma.sql`AND priority = ${filters.priority}`
            : Prisma.empty
        }
      ORDER BY rank DESC, created_at DESC
      LIMIT ${limit} OFFSET ${offset}
    `
  }

  // æ•°æ®å½’æ¡£
  async archiveOldData(retentionDays: number = 365) {
    const cutoffDate = new Date()
    cutoffDate.setDate(cutoffDate.getDate() - retentionDays)

    return this.$transaction(async (tx) => {
      // å½’æ¡£æ—§çš„æœç´¢å†å²
      const archivedSearchHistory = await tx.searchHistory.deleteMany({
        where: {
          createdAt: {
            lt: cutoffDate,
          },
        },
      })

      // å½’æ¡£æ—§çš„å®‰å…¨æ—¥å¿—
      const archivedSecurityLogs = await tx.securityLog.deleteMany({
        where: {
          createdAt: {
            lt: cutoffDate,
          },
          resolved: true,
        },
      })

      return {
        searchHistoryArchived: archivedSearchHistory.count,
        securityLogsArchived: archivedSecurityLogs.count,
      }
    })
  }
}
```

## ğŸ“Š ç¼“å­˜ç­–ç•¥

### Redis ç¼“å­˜æœåŠ¡

```typescript
// apps/backend/src/cache/cache.service.ts
import { Injectable, OnModuleInit } from '@nestjs/common'
import { ConfigService } from '@nestjs/config'
import Redis from 'ioredis'
import { DatabaseService } from '../database/database.service'

@Injectable()
export class CacheService implements OnModuleInit {
  private redis: Redis
  private readonly defaultTTL = 3600 // 1å°æ—¶

  constructor(
    private configService: ConfigService,
    private databaseService: DatabaseService
  ) {}

  async onModuleInit() {
    this.redis = new Redis({
      host: this.configService.get('REDIS_HOST', 'localhost'),
      port: this.configService.get('REDIS_PORT', 6379),
      password: this.configService.get('REDIS_PASSWORD'),
      db: this.configService.get('REDIS_DB', 0),
      retryDelayOnFailover: 100,
      maxRetriesPerRequest: 3,
      lazyConnect: true,
      keepAlive: 30000,

      // è¿æ¥æ± é…ç½®
      family: 4,
      connectTimeout: 10000,
      commandTimeout: 5000,

      // é‡è¿ç­–ç•¥
      retryStrategy: (times) => {
        const delay = Math.min(times * 50, 2000)
        return delay
      },
    })

    // è¿æ¥äº‹ä»¶ç›‘å¬
    this.redis.on('connect', () => {
      console.log('Redis connected')
    })

    this.redis.on('error', (err) => {
      console.error('Redis error:', err)
    })

    await this.redis.connect()
  }

  // åŸºç¡€ç¼“å­˜æ“ä½œ
  async get<T>(key: string): Promise<T | null> {
    try {
      const value = await this.redis.get(key)
      return value ? JSON.parse(value) : null
    } catch (error) {
      console.error(`Cache get error for key ${key}:`, error)
      return null
    }
  }

  async set(
    key: string,
    value: any,
    ttl: number = this.defaultTTL
  ): Promise<void> {
    try {
      await this.redis.setex(key, ttl, JSON.stringify(value))
    } catch (error) {
      console.error(`Cache set error for key ${key}:`, error)
    }
  }

  async del(key: string): Promise<void> {
    try {
      await this.redis.del(key)
    } catch (error) {
      console.error(`Cache delete error for key ${key}:`, error)
    }
  }

  async exists(key: string): Promise<boolean> {
    try {
      const result = await this.redis.exists(key)
      return result === 1
    } catch (error) {
      console.error(`Cache exists error for key ${key}:`, error)
      return false
    }
  }

  async increment(key: string, value: number = 1): Promise<number> {
    try {
      return await this.redis.incrby(key, value)
    } catch (error) {
      console.error(`Cache increment error for key ${key}:`, error)
      return 0
    }
  }

  // ç¼“å­˜æ¨¡å¼å®ç°

  // Cache-Aside æ¨¡å¼
  async getOrSet<T>(
    key: string,
    fetcher: () => Promise<T>,
    ttl: number = this.defaultTTL
  ): Promise<T> {
    // å…ˆä»ç¼“å­˜è·å–
    let value = await this.get<T>(key)

    if (value === null) {
      // ç¼“å­˜æœªå‘½ä¸­ï¼Œä»æ•°æ®æºè·å–
      value = await fetcher()

      // å†™å…¥ç¼“å­˜
      if (value !== null && value !== undefined) {
        await this.set(key, value, ttl)
      }
    }

    return value
  }

  // Write-Through æ¨¡å¼
  async setWithWriteThrough<T>(
    key: string,
    value: T,
    writer: (value: T) => Promise<void>,
    ttl: number = this.defaultTTL
  ): Promise<void> {
    // åŒæ—¶å†™å…¥ç¼“å­˜å’Œæ•°æ®åº“
    await Promise.all([this.set(key, value, ttl), writer(value)])
  }

  // Write-Behind æ¨¡å¼
  async setWithWriteBehind<T>(
    key: string,
    value: T,
    writer: (value: T) => Promise<void>,
    ttl: number = this.defaultTTL
  ): Promise<void> {
    // å…ˆå†™å…¥ç¼“å­˜
    await this.set(key, value, ttl)

    // å¼‚æ­¥å†™å…¥æ•°æ®åº“
    setImmediate(async () => {
      try {
        await writer(value)
      } catch (error) {
        console.error('Write-behind error:', error)
        // å¯ä»¥å®ç°é‡è¯•æœºåˆ¶æˆ–æ­»ä¿¡é˜Ÿåˆ—
      }
    })
  }

  // åˆ†å¸ƒå¼é”
  async acquireLock(key: string, ttl: number = 30): Promise<string | null> {
    const lockKey = `lock:${key}`
    const lockValue = `${Date.now()}-${Math.random()}`

    const result = await this.redis.set(lockKey, lockValue, 'EX', ttl, 'NX')
    return result === 'OK' ? lockValue : null
  }

  async releaseLock(key: string, lockValue: string): Promise<boolean> {
    const lockKey = `lock:${key}`

    const script = `
      if redis.call('get', KEYS[1]) == ARGV[1] then
        return redis.call('del', KEYS[1])
      else
        return 0
      end
    `

    const result = await this.redis.eval(script, 1, lockKey, lockValue)
    return result === 1
  }

  // ç¼“å­˜é¢„çƒ­
  async warmupCache(userId: string): Promise<void> {
    try {
      // é¢„åŠ è½½ç”¨æˆ·å¸¸ç”¨æ•°æ®
      const [user, todos, settings] = await Promise.all([
        this.databaseService.user.findUnique({ where: { id: userId } }),
        this.databaseService.todo.findMany({
          where: { userId, completed: false },
          take: 50,
          orderBy: { createdAt: 'desc' },
        }),
        this.databaseService.userSettings.findUnique({ where: { userId } }),
      ])

      // å†™å…¥ç¼“å­˜
      await Promise.all([
        this.set(`user:${userId}`, user, 1800), // 30åˆ†é’Ÿ
        this.set(`todos:${userId}:active`, todos, 900), // 15åˆ†é’Ÿ
        this.set(`settings:${userId}`, settings, 3600), // 1å°æ—¶
      ])
    } catch (error) {
      console.error('Cache warmup error:', error)
    }
  }

  // ç¼“å­˜å¤±æ•ˆ
  async invalidateUserCache(userId: string): Promise<void> {
    const patterns = [
      `user:${userId}`,
      `todos:${userId}:*`,
      `settings:${userId}`,
      `stats:${userId}:*`,
    ]

    for (const pattern of patterns) {
      if (pattern.includes('*')) {
        const keys = await this.redis.keys(pattern)
        if (keys.length > 0) {
          await this.redis.del(...keys)
        }
      } else {
        await this.del(pattern)
      }
    }
  }

  // ç¼“å­˜ç»Ÿè®¡
  async getCacheStats(): Promise<any> {
    const info = await this.redis.info('stats')
    const memory = await this.redis.info('memory')

    return {
      connections: await this.redis.info('clients'),
      stats: info,
      memory: memory,
      keyspace: await this.redis.info('keyspace'),
    }
  }
}
```

### æŸ¥è¯¢ç¼“å­˜è£…é¥°å™¨

```typescript
// apps/backend/src/cache/cache.decorator.ts
import { SetMetadata } from '@nestjs/common'

export const CACHE_KEY = 'cache_key'
export const CACHE_TTL = 'cache_ttl'

export const Cacheable = (key: string, ttl: number = 3600) => {
  return (
    target: any,
    propertyName: string,
    descriptor: PropertyDescriptor
  ) => {
    SetMetadata(CACHE_KEY, key)(target, propertyName, descriptor)
    SetMetadata(CACHE_TTL, ttl)(target, propertyName, descriptor)

    const method = descriptor.value

    descriptor.value = async function (...args: any[]) {
      const cacheService = this.cacheService
      if (!cacheService) {
        return method.apply(this, args)
      }

      // ç”Ÿæˆç¼“å­˜é”®
      const cacheKey = key.replace(/\{(\d+)\}/g, (match, index) => {
        return args[parseInt(index)] || match
      })

      // å°è¯•ä»ç¼“å­˜è·å–
      const cached = await cacheService.get(cacheKey)
      if (cached !== null) {
        return cached
      }

      // æ‰§è¡ŒåŸæ–¹æ³•
      const result = await method.apply(this, args)

      // å†™å…¥ç¼“å­˜
      if (result !== null && result !== undefined) {
        await cacheService.set(cacheKey, result, ttl)
      }

      return result
    }

    return descriptor
  }
}

// ä½¿ç”¨ç¤ºä¾‹
export class TodosService {
  constructor(private cacheService: CacheService) {}

  @Cacheable('todos:user:{0}:active', 900) // 15åˆ†é’Ÿç¼“å­˜
  async getActiveTodos(userId: string) {
    return this.databaseService.todo.findMany({
      where: { userId, completed: false },
      orderBy: { createdAt: 'desc' },
    })
  }

  @Cacheable('stats:user:{0}:daily', 1800) // 30åˆ†é’Ÿç¼“å­˜
  async getDailyStats(userId: string) {
    return this.databaseService.getTodoStatistics(userId, {
      start: new Date(new Date().setHours(0, 0, 0, 0)),
      end: new Date(new Date().setHours(23, 59, 59, 999)),
    })
  }
}
```

## ğŸ”„ æ•°æ®åŒæ­¥ä¸å¤‡ä»½

### æ•°æ®å¤‡ä»½ç­–ç•¥

```typescript
// apps/backend/src/database/backup.service.ts
import { Injectable } from '@nestjs/common'
import { ConfigService } from '@nestjs/config'
import { exec } from 'child_process'
import { promisify } from 'util'
import * as fs from 'fs/promises'
import * as path from 'path'
import * as crypto from 'crypto'

const execAsync = promisify(exec)

@Injectable()
export class BackupService {
  private readonly backupDir: string
  private readonly encryptionKey: string

  constructor(private configService: ConfigService) {
    this.backupDir = this.configService.get('BACKUP_DIR', './backups')
    this.encryptionKey = this.configService.get('BACKUP_ENCRYPTION_KEY')
  }

  // å…¨é‡å¤‡ä»½
  async createFullBackup(): Promise<string> {
    const timestamp = new Date().toISOString().replace(/[:.]/g, '-')
    const backupFile = path.join(this.backupDir, `full-backup-${timestamp}.sql`)
    const encryptedFile = `${backupFile}.enc`

    try {
      // ç¡®ä¿å¤‡ä»½ç›®å½•å­˜åœ¨
      await fs.mkdir(this.backupDir, { recursive: true })

      // æ‰§è¡Œ pg_dump
      const databaseUrl = this.configService.get('DATABASE_URL')
      const command = `pg_dump "${databaseUrl}" --no-password --verbose --clean --no-acl --no-owner -f "${backupFile}"`

      await execAsync(command)

      // åŠ å¯†å¤‡ä»½æ–‡ä»¶
      await this.encryptFile(backupFile, encryptedFile)

      // åˆ é™¤æœªåŠ å¯†æ–‡ä»¶
      await fs.unlink(backupFile)

      // éªŒè¯å¤‡ä»½æ–‡ä»¶
      const stats = await fs.stat(encryptedFile)
      if (stats.size === 0) {
        throw new Error('å¤‡ä»½æ–‡ä»¶ä¸ºç©º')
      }

      console.log(`Full backup created: ${encryptedFile} (${stats.size} bytes)`)
      return encryptedFile
    } catch (error) {
      console.error('Full backup failed:', error)
      throw error
    }
  }

  // å¢é‡å¤‡ä»½ï¼ˆåŸºäº WALï¼‰
  async createIncrementalBackup(): Promise<string> {
    const timestamp = new Date().toISOString().replace(/[:.]/g, '-')
    const backupFile = path.join(
      this.backupDir,
      `incremental-backup-${timestamp}.tar.gz`
    )

    try {
      // ä½¿ç”¨ pg_basebackup åˆ›å»ºå¢é‡å¤‡ä»½
      const command = `pg_basebackup -D "${backupFile}" -Ft -z -P -v`
      await execAsync(command)

      console.log(`Incremental backup created: ${backupFile}`)
      return backupFile
    } catch (error) {
      console.error('Incremental backup failed:', error)
      throw error
    }
  }

  // æ•°æ®å¯¼å‡º
  async exportUserData(userId: string): Promise<string> {
    const timestamp = new Date().toISOString().replace(/[:.]/g, '-')
    const exportFile = path.join(
      this.backupDir,
      `user-export-${userId}-${timestamp}.json`
    )

    try {
      // å¯¼å‡ºç”¨æˆ·ç›¸å…³æ•°æ®
      const userData = await this.databaseService.$transaction(async (tx) => {
        const [user, todos, settings, searchHistory] = await Promise.all([
          tx.user.findUnique({
            where: { id: userId },
            select: {
              id: true,
              email: true,
              name: true,
              preferences: true,
              createdAt: true,
            },
          }),
          tx.todo.findMany({ where: { userId } }),
          tx.userSettings.findUnique({ where: { userId } }),
          tx.searchHistory.findMany({
            where: { userId },
            orderBy: { createdAt: 'desc' },
            take: 1000, // é™åˆ¶å¯¼å‡ºæ•°é‡
          }),
        ])

        return { user, todos, settings, searchHistory }
      })

      // å†™å…¥æ–‡ä»¶
      await fs.writeFile(exportFile, JSON.stringify(userData, null, 2))

      console.log(`User data exported: ${exportFile}`)
      return exportFile
    } catch (error) {
      console.error('User data export failed:', error)
      throw error
    }
  }

  // å¤‡ä»½æ¢å¤
  async restoreBackup(backupFile: string): Promise<void> {
    try {
      let sqlFile = backupFile

      // å¦‚æœæ˜¯åŠ å¯†æ–‡ä»¶ï¼Œå…ˆè§£å¯†
      if (backupFile.endsWith('.enc')) {
        sqlFile = backupFile.replace('.enc', '')
        await this.decryptFile(backupFile, sqlFile)
      }

      // æ‰§è¡Œæ¢å¤
      const databaseUrl = this.configService.get('DATABASE_URL')
      const command = `psql "${databaseUrl}" -f "${sqlFile}"`

      await execAsync(command)

      // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
      if (sqlFile !== backupFile) {
        await fs.unlink(sqlFile)
      }

      console.log(`Backup restored from: ${backupFile}`)
    } catch (error) {
      console.error('Backup restore failed:', error)
      throw error
    }
  }

  // æ¸…ç†æ—§å¤‡ä»½
  async cleanupOldBackups(retentionDays: number = 30): Promise<void> {
    try {
      const files = await fs.readdir(this.backupDir)
      const cutoffDate = new Date()
      cutoffDate.setDate(cutoffDate.getDate() - retentionDays)

      for (const file of files) {
        const filePath = path.join(this.backupDir, file)
        const stats = await fs.stat(filePath)

        if (stats.mtime < cutoffDate) {
          await fs.unlink(filePath)
          console.log(`Deleted old backup: ${file}`)
        }
      }
    } catch (error) {
      console.error('Backup cleanup failed:', error)
    }
  }

  // æ–‡ä»¶åŠ å¯†
  private async encryptFile(
    inputFile: string,
    outputFile: string
  ): Promise<void> {
    const algorithm = 'aes-256-gcm'
    const key = crypto.scryptSync(this.encryptionKey, 'salt', 32)
    const iv = crypto.randomBytes(16)

    const cipher = crypto.createCipher(algorithm, key)
    cipher.setAAD(Buffer.from('backup', 'utf8'))

    const input = await fs.readFile(inputFile)
    const encrypted = Buffer.concat([cipher.update(input), cipher.final()])
    const tag = cipher.getAuthTag()

    // ç»„åˆ IV + Tag + åŠ å¯†æ•°æ®
    const output = Buffer.concat([iv, tag, encrypted])
    await fs.writeFile(outputFile, output)
  }

  // æ–‡ä»¶è§£å¯†
  private async decryptFile(
    inputFile: string,
    outputFile: string
  ): Promise<void> {
    const algorithm = 'aes-256-gcm'
    const key = crypto.scryptSync(this.encryptionKey, 'salt', 32)

    const input = await fs.readFile(inputFile)
    const iv = input.slice(0, 16)
    const tag = input.slice(16, 32)
    const encrypted = input.slice(32)

    const decipher = crypto.createDecipher(algorithm, key)
    decipher.setAAD(Buffer.from('backup', 'utf8'))
    decipher.setAuthTag(tag)

    const decrypted = Buffer.concat([
      decipher.update(encrypted),
      decipher.final(),
    ])
    await fs.writeFile(outputFile, decrypted)
  }
}
```

## ğŸ¯ æ ¸å¿ƒå­¦ä¹ è¦ç‚¹

### 1. æ•°æ®åº“è®¾è®¡

- **Schema è®¾è®¡**ï¼šè§„èŒƒåŒ–ä¸åè§„èŒƒåŒ–å¹³è¡¡
- **ç´¢å¼•ç­–ç•¥**ï¼šå¤åˆç´¢å¼•ã€éƒ¨åˆ†ç´¢å¼•ã€è¡¨è¾¾å¼ç´¢å¼•
- **åˆ†åŒºè¡¨**ï¼šæ—¶é—´åˆ†åŒºã€èŒƒå›´åˆ†åŒº
- **çº¦æŸè®¾è®¡**ï¼šå¤–é”®ã€å”¯ä¸€çº¦æŸã€æ£€æŸ¥çº¦æŸ

### 2. æŸ¥è¯¢ä¼˜åŒ–

- **SQL ä¼˜åŒ–**ï¼šæ‰§è¡Œè®¡åˆ’åˆ†æã€æ…¢æŸ¥è¯¢ä¼˜åŒ–
- **ORM ä¼˜åŒ–**ï¼šN+1 é—®é¢˜è§£å†³ã€æ‰¹é‡æ“ä½œ
- **å…¨æ–‡æœç´¢**ï¼šPostgreSQL FTSã€æœç´¢æ’åº
- **åˆ†é¡µä¼˜åŒ–**ï¼šæ¸¸æ ‡åˆ†é¡µã€åç§»åˆ†é¡µ

### 3. ç¼“å­˜æ¶æ„

- **ç¼“å­˜æ¨¡å¼**ï¼šCache-Asideã€Write-Throughã€Write-Behind
- **ç¼“å­˜ç­–ç•¥**ï¼šTTL è®¾ç½®ã€ç¼“å­˜é¢„çƒ­ã€ç¼“å­˜å¤±æ•ˆ
- **åˆ†å¸ƒå¼ç¼“å­˜**ï¼šRedis é›†ç¾¤ã€ä¸€è‡´æ€§å“ˆå¸Œ
- **ç¼“å­˜ç›‘æ§**ï¼šå‘½ä¸­ç‡ã€æ€§èƒ½æŒ‡æ ‡

### 4. æ•°æ®å®‰å…¨

- **å¤‡ä»½ç­–ç•¥**ï¼šå…¨é‡å¤‡ä»½ã€å¢é‡å¤‡ä»½ã€å®æ—¶å¤‡ä»½
- **æ•°æ®åŠ å¯†**ï¼šé™æ€åŠ å¯†ã€ä¼ è¾“åŠ å¯†
- **è®¿é—®æ§åˆ¶**ï¼šè¡Œçº§å®‰å…¨ã€åˆ—çº§æƒé™
- **å®¡è®¡æ—¥å¿—**ï¼šæ“ä½œè®°å½•ã€å˜æ›´è¿½è¸ª

### 5. æ€§èƒ½ç›‘æ§

- **æ•°æ®åº“ç›‘æ§**ï¼šè¿æ¥æ± ã€æ…¢æŸ¥è¯¢ã€é”ç­‰å¾…
- **ç¼“å­˜ç›‘æ§**ï¼šå†…å­˜ä½¿ç”¨ã€å‘½ä¸­ç‡ã€å»¶è¿Ÿ
- **å®¹é‡è§„åˆ’**ï¼šå­˜å‚¨å¢é•¿ã€æ€§èƒ½é¢„æµ‹
- **æ•…éšœæ¢å¤**ï¼šä¸»ä»åˆ‡æ¢ã€æ•°æ®æ¢å¤

## ğŸ“ ç®€å†æŠ€æœ¯äº®ç‚¹

### æ•°æ®åº“æ¶æ„äº®ç‚¹

- **PostgreSQL é«˜çº§ç‰¹æ€§**ï¼šJSONBã€å…¨æ–‡æœç´¢ã€åˆ†åŒºè¡¨
- **Prisma ORM ä¼˜åŒ–**ï¼šç±»å‹å®‰å…¨ã€æŸ¥è¯¢ä¼˜åŒ–ã€äº‹åŠ¡ç®¡ç†
- **ç´¢å¼•ä¼˜åŒ–ç­–ç•¥**ï¼šå¤åˆç´¢å¼•ã€éƒ¨åˆ†ç´¢å¼•ã€GIN ç´¢å¼•
- **åˆ†åŒºè¡¨è®¾è®¡**ï¼šæ—¶é—´åˆ†åŒºã€è‡ªåŠ¨åˆ†åŒºç®¡ç†

### ç¼“å­˜æ¶æ„äº®ç‚¹

- **Redis ç¼“å­˜ç­–ç•¥**ï¼šå¤šç§ç¼“å­˜æ¨¡å¼å®ç°
- **åˆ†å¸ƒå¼é”**ï¼šRedis åˆ†å¸ƒå¼é”æœºåˆ¶
- **ç¼“å­˜è£…é¥°å™¨**ï¼šAOP ç¼“å­˜æŠ½è±¡
- **ç¼“å­˜é¢„çƒ­**ï¼šæ™ºèƒ½ç¼“å­˜é¢„åŠ è½½

### æ•°æ®å®‰å…¨äº®ç‚¹

- **è‡ªåŠ¨å¤‡ä»½ç³»ç»Ÿ**ï¼šå…¨é‡+å¢é‡å¤‡ä»½ç­–ç•¥
- **æ•°æ®åŠ å¯†**ï¼šå¤‡ä»½æ–‡ä»¶åŠ å¯†ä¿æŠ¤
- **æ•°æ®å¯¼å‡º**ï¼šGDPR åˆè§„æ•°æ®å¯¼å‡º
- **æ•…éšœæ¢å¤**ï¼šè‡ªåŠ¨åŒ–æ¢å¤æµç¨‹
