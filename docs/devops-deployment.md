# DevOps ä¸éƒ¨ç½²è§£å†³æ–¹æ¡ˆï¼šç°ä»£åŒ– CI/CD æµæ°´çº¿

## æŠ€æœ¯æ¦‚è¿°

æœ¬é¡¹ç›®é‡‡ç”¨ç°ä»£åŒ–çš„ DevOps å®è·µï¼ŒåŒ…æ‹¬å®¹å™¨åŒ–éƒ¨ç½²ã€è‡ªåŠ¨åŒ– CI/CD æµæ°´çº¿ã€ç›‘æ§å‘Šè­¦ã€æ—¥å¿—æ”¶é›†ç­‰ï¼Œå®ç°äº†ä»å¼€å‘åˆ°ç”Ÿäº§çš„å…¨æµç¨‹è‡ªåŠ¨åŒ–ç®¡ç†ã€‚

## ğŸ³ å®¹å™¨åŒ–æ¶æ„

### æ•´ä½“æ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    è´Ÿè½½å‡è¡¡å±‚                                â”‚
â”‚  â”œâ”€ Nginx Proxy      â”œâ”€ SSL Termination                   â”‚
â”‚  â”œâ”€ Rate Limiting     â”œâ”€ Static Assets                     â”‚
â”‚  â””â”€ Health Checks     â””â”€ Request Routing                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    åº”ç”¨å®¹å™¨å±‚                                â”‚
â”‚  â”œâ”€ Frontend (Vue)    â”œâ”€ Backend (NestJS)                  â”‚
â”‚  â”œâ”€ Mobile (Capacitor)â”œâ”€ Desktop (Electron)                â”‚
â”‚  â””â”€ AI Services       â””â”€ Background Jobs                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    æ•°æ®å­˜å‚¨å±‚                                â”‚
â”‚  â”œâ”€ PostgreSQL       â”œâ”€ Redis Cache                        â”‚
â”‚  â”œâ”€ File Storage     â”œâ”€ Backup Storage                     â”‚
â”‚  â””â”€ Log Storage       â””â”€ Metrics Storage                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    ç›‘æ§è§‚æµ‹å±‚                                â”‚
â”‚  â”œâ”€ Prometheus       â”œâ”€ Grafana                            â”‚
â”‚  â”œâ”€ Loki Logs        â”œâ”€ Jaeger Tracing                     â”‚
â”‚  â””â”€ AlertManager     â””â”€ Health Monitoring                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Docker é…ç½®

#### å‰ç«¯ Dockerfile

```dockerfile
# apps/frontend/Dockerfile
# å¤šé˜¶æ®µæ„å»ºï¼Œä¼˜åŒ–é•œåƒå¤§å°
FROM node:18-alpine AS builder

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å¤åˆ¶ package æ–‡ä»¶
COPY package*.json ./
COPY packages/shared/package*.json ./packages/shared/

# å®‰è£…ä¾èµ–
RUN npm ci --only=production && npm cache clean --force

# å¤åˆ¶æºä»£ç 
COPY . .

# æ„å»ºåº”ç”¨
RUN npm run build:frontend

# ç”Ÿäº§é˜¶æ®µ
FROM nginx:alpine AS production

# å®‰è£…å¿…è¦å·¥å…·
RUN apk add --no-cache curl

# å¤åˆ¶æ„å»ºäº§ç‰©
COPY --from=builder /app/apps/frontend/dist /usr/share/nginx/html

# å¤åˆ¶ Nginx é…ç½®
COPY apps/frontend/nginx.conf /etc/nginx/nginx.conf
COPY apps/frontend/default.conf /etc/nginx/conf.d/default.conf

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD curl -f http://localhost/ || exit 1

# æš´éœ²ç«¯å£
EXPOSE 80

# å¯åŠ¨å‘½ä»¤
CMD ["nginx", "-g", "daemon off;"]
```

#### åç«¯ Dockerfile

```dockerfile
# apps/backend/Dockerfile
FROM node:18-alpine AS builder

WORKDIR /app

# å¤åˆ¶ package æ–‡ä»¶
COPY package*.json ./
COPY packages/shared/package*.json ./packages/shared/
COPY apps/backend/package*.json ./apps/backend/

# å®‰è£…ä¾èµ–
RUN npm ci --only=production

# å¤åˆ¶æºä»£ç 
COPY . .

# ç”Ÿæˆ Prisma å®¢æˆ·ç«¯
RUN npx prisma generate --schema=./apps/backend/prisma/schema.prisma

# æ„å»ºåº”ç”¨
RUN npm run build:backend

# ç”Ÿäº§é˜¶æ®µ
FROM node:18-alpine AS production

# åˆ›å»ºåº”ç”¨ç”¨æˆ·
RUN addgroup -g 1001 -S nodejs
RUN adduser -S nestjs -u 1001

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å¤åˆ¶æ„å»ºäº§ç‰©å’Œä¾èµ–
COPY --from=builder --chown=nestjs:nodejs /app/node_modules ./node_modules
COPY --from=builder --chown=nestjs:nodejs /app/apps/backend/dist ./dist
COPY --from=builder --chown=nestjs:nodejs /app/apps/backend/prisma ./prisma
COPY --from=builder --chown=nestjs:nodejs /app/package*.json ./

# å®‰è£…ç”Ÿäº§ä¾èµ–
RUN npm ci --only=production && npm cache clean --force

# åˆ‡æ¢åˆ°åº”ç”¨ç”¨æˆ·
USER nestjs

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD curl -f http://localhost:3000/health || exit 1

# æš´éœ²ç«¯å£
EXPOSE 3000

# å¯åŠ¨å‘½ä»¤
CMD ["node", "dist/main.js"]
```

#### Docker Compose é…ç½®

```yaml
# docker-compose.yml
version: '3.8'

services:
  # å‰ç«¯æœåŠ¡
  frontend:
    build:
      context: .
      dockerfile: apps/frontend/Dockerfile
    container_name: yun-todolist-frontend
    ports:
      - '80:80'
      - '443:443'
    environment:
      - NODE_ENV=production
    volumes:
      - ./ssl:/etc/nginx/ssl:ro
    depends_on:
      - backend
    networks:
      - app-network
    restart: unless-stopped
    labels:
      - 'traefik.enable=true'
      - 'traefik.http.routers.frontend.rule=Host(`todolist.example.com`)'
      - 'traefik.http.routers.frontend.tls=true'
      - 'traefik.http.routers.frontend.tls.certresolver=letsencrypt'

  # åç«¯æœåŠ¡
  backend:
    build:
      context: .
      dockerfile: apps/backend/Dockerfile
    container_name: yun-todolist-backend
    ports:
      - '3000:3000'
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgresql://postgres:${POSTGRES_PASSWORD}@postgres:5432/todolist
      - REDIS_URL=redis://redis:6379
      - JWT_SECRET=${JWT_SECRET}
      - DEEPSEEK_API_KEY=${DEEPSEEK_API_KEY}
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - app-network
    restart: unless-stopped
    volumes:
      - ./logs:/app/logs
    labels:
      - 'traefik.enable=true'
      - 'traefik.http.routers.backend.rule=Host(`api.todolist.example.com`)'
      - 'traefik.http.routers.backend.tls=true'

  # PostgreSQL æ•°æ®åº“
  postgres:
    image: postgres:15-alpine
    container_name: yun-todolist-postgres
    environment:
      - POSTGRES_DB=todolist
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - PGDATA=/var/lib/postgresql/data/pgdata
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./backups:/backups
    ports:
      - '5432:5432'
    networks:
      - app-network
    restart: unless-stopped
    healthcheck:
      test: ['CMD-SHELL', 'pg_isready -U postgres']
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis ç¼“å­˜
  redis:
    image: redis:7-alpine
    container_name: yun-todolist-redis
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD}
    volumes:
      - redis_data:/data
    ports:
      - '6379:6379'
    networks:
      - app-network
    restart: unless-stopped
    healthcheck:
      test: ['CMD', 'redis-cli', 'ping']
      interval: 10s
      timeout: 3s
      retries: 5

  # Nginx åå‘ä»£ç†
  nginx:
    image: nginx:alpine
    container_name: yun-todolist-nginx
    ports:
      - '80:80'
      - '443:443'
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/conf.d:/etc/nginx/conf.d:ro
      - ./ssl:/etc/nginx/ssl:ro
      - ./logs/nginx:/var/log/nginx
    depends_on:
      - frontend
      - backend
    networks:
      - app-network
    restart: unless-stopped

  # ç›‘æ§æœåŠ¡
  prometheus:
    image: prom/prometheus:latest
    container_name: yun-todolist-prometheus
    ports:
      - '9090:9090'
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    networks:
      - app-network
    restart: unless-stopped

  # Grafana ä»ªè¡¨æ¿
  grafana:
    image: grafana/grafana:latest
    container_name: yun-todolist-grafana
    ports:
      - '3001:3000'
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources
    networks:
      - app-network
    restart: unless-stopped

volumes:
  postgres_data:
  redis_data:
  prometheus_data:
  grafana_data:

networks:
  app-network:
    driver: bridge
```

## ğŸš€ CI/CD æµæ°´çº¿

### GitHub Actions é…ç½®

```yaml
# .github/workflows/ci-cd.yml
name: CI/CD Pipeline

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  # ä»£ç è´¨é‡æ£€æŸ¥
  quality-check:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run linting
        run: npm run lint

      - name: Run type checking
        run: npm run type-check

      - name: Run tests
        run: npm run test:coverage

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage/lcov.info
          flags: unittests
          name: codecov-umbrella

  # å®‰å…¨æ‰«æ
  security-scan:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'sarif'
          output: 'trivy-results.sarif'

      - name: Upload Trivy scan results
        uses: github/codeql-action/upload-sarif@v2
        with:
          sarif_file: 'trivy-results.sarif'

      - name: Run npm audit
        run: npm audit --audit-level=high

  # æ„å»ºé•œåƒ
  build:
    needs: [quality-check, security-scan]
    runs-on: ubuntu-latest
    strategy:
      matrix:
        service: [frontend, backend]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images:
            ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}-${{ matrix.service }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=sha,prefix={{branch}}-
            type=raw,value=latest,enable={{is_default_branch}}

      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./apps/${{ matrix.service }}/Dockerfile
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          platforms: linux/amd64,linux/arm64

  # éƒ¨ç½²åˆ°æµ‹è¯•ç¯å¢ƒ
  deploy-staging:
    needs: build
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/develop'
    environment: staging
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Deploy to staging
        uses: appleboy/ssh-action@v1.0.0
        with:
          host: ${{ secrets.STAGING_HOST }}
          username: ${{ secrets.STAGING_USER }}
          key: ${{ secrets.STAGING_SSH_KEY }}
          script: |
            cd /opt/yun-todolist
            git pull origin develop
            docker-compose -f docker-compose.staging.yml pull
            docker-compose -f docker-compose.staging.yml up -d
            docker system prune -f

      - name: Run health checks
        run: |
          sleep 30
          curl -f ${{ secrets.STAGING_URL }}/health || exit 1

  # éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ
  deploy-production:
    needs: build
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    environment: production
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Deploy to production
        uses: appleboy/ssh-action@v1.0.0
        with:
          host: ${{ secrets.PRODUCTION_HOST }}
          username: ${{ secrets.PRODUCTION_USER }}
          key: ${{ secrets.PRODUCTION_SSH_KEY }}
          script: |
            cd /opt/yun-todolist
            git pull origin main
            docker-compose pull
            docker-compose up -d
            docker system prune -f

      - name: Run smoke tests
        run: |
          sleep 60
          curl -f ${{ secrets.PRODUCTION_URL }}/health || exit 1
          curl -f ${{ secrets.PRODUCTION_URL }}/api/health || exit 1

      - name: Notify deployment
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ job.status }}
          channel: '#deployments'
          webhook_url: ${{ secrets.SLACK_WEBHOOK }}
        if: always()
```

### éƒ¨ç½²è„šæœ¬

```bash
#!/bin/bash
# scripts/deploy.sh

set -e

# é…ç½®å˜é‡
ENVIRONMENT=${1:-staging}
VERSION=${2:-latest}
COMPOSE_FILE="docker-compose.${ENVIRONMENT}.yml"

echo "ğŸš€ å¼€å§‹éƒ¨ç½²åˆ° ${ENVIRONMENT} ç¯å¢ƒ..."

# æ£€æŸ¥ç¯å¢ƒ
if [[ ! -f "$COMPOSE_FILE" ]]; then
    echo "âŒ æ‰¾ä¸åˆ°é…ç½®æ–‡ä»¶: $COMPOSE_FILE"
    exit 1
fi

# å¤‡ä»½å½“å‰ç‰ˆæœ¬
echo "ğŸ“¦ å¤‡ä»½å½“å‰ç‰ˆæœ¬..."
docker-compose -f $COMPOSE_FILE ps --format "table {{.Name}}\t{{.Image}}" > backup/deployment-${ENVIRONMENT}-$(date +%Y%m%d-%H%M%S).txt

# æ‹‰å–æœ€æ–°é•œåƒ
echo "ğŸ“¥ æ‹‰å–æœ€æ–°é•œåƒ..."
docker-compose -f $COMPOSE_FILE pull

# æ•°æ®åº“è¿ç§»
if [[ "$ENVIRONMENT" == "production" ]]; then
    echo "ğŸ—„ï¸ æ‰§è¡Œæ•°æ®åº“è¿ç§»..."
    docker-compose -f $COMPOSE_FILE run --rm backend npm run prisma:migrate:deploy
fi

# æ»šåŠ¨æ›´æ–°
echo "ğŸ”„ æ‰§è¡Œæ»šåŠ¨æ›´æ–°..."
docker-compose -f $COMPOSE_FILE up -d --remove-orphans

# å¥åº·æ£€æŸ¥
echo "ğŸ¥ æ‰§è¡Œå¥åº·æ£€æŸ¥..."
sleep 30

for service in frontend backend; do
    if ! docker-compose -f $COMPOSE_FILE exec $service curl -f http://localhost/health; then
        echo "âŒ $service å¥åº·æ£€æŸ¥å¤±è´¥"
        echo "ğŸ”„ å›æ»šåˆ°ä¸Šä¸€ç‰ˆæœ¬..."
        docker-compose -f $COMPOSE_FILE down
        # è¿™é‡Œå¯ä»¥æ·»åŠ å›æ»šé€»è¾‘
        exit 1
    fi
done

# æ¸…ç†æ—§é•œåƒ
echo "ğŸ§¹ æ¸…ç†æ—§é•œåƒ..."
docker system prune -f

echo "âœ… éƒ¨ç½²å®Œæˆï¼"

# å‘é€é€šçŸ¥
if command -v curl &> /dev/null && [[ -n "$SLACK_WEBHOOK" ]]; then
    curl -X POST -H 'Content-type: application/json' \
        --data "{\"text\":\"âœ… ${ENVIRONMENT} ç¯å¢ƒéƒ¨ç½²æˆåŠŸ - ç‰ˆæœ¬: ${VERSION}\"}" \
        $SLACK_WEBHOOK
fi
```

## ğŸ“Š ç›‘æ§ä¸è§‚æµ‹

### Prometheus é…ç½®

```yaml
# monitoring/prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - 'alert_rules.yml'

alerting:
  alertmanagers:
    - static_configs:
        - targets:
            - alertmanager:9093

scrape_configs:
  # Prometheus è‡ªç›‘æ§
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  # åº”ç”¨ç›‘æ§
  - job_name: 'yun-todolist-backend'
    static_configs:
      - targets: ['backend:3000']
    metrics_path: '/metrics'
    scrape_interval: 10s

  # Node Exporter
  - job_name: 'node-exporter'
    static_configs:
      - targets: ['node-exporter:9100']

  # Docker ç›‘æ§
  - job_name: 'docker'
    static_configs:
      - targets: ['docker-exporter:9323']

  # PostgreSQL ç›‘æ§
  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres-exporter:9187']

  # Redis ç›‘æ§
  - job_name: 'redis'
    static_configs:
      - targets: ['redis-exporter:9121']

  # Nginx ç›‘æ§
  - job_name: 'nginx'
    static_configs:
      - targets: ['nginx-exporter:9113']
```

### å‘Šè­¦è§„åˆ™

```yaml
# monitoring/alert_rules.yml
groups:
  - name: application.rules
    rules:
      # åº”ç”¨å¯ç”¨æ€§å‘Šè­¦
      - alert: ApplicationDown
        expr: up{job="yun-todolist-backend"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: 'åº”ç”¨æœåŠ¡ä¸å¯ç”¨'
          description: '{{ $labels.instance }} åº”ç”¨æœåŠ¡å·²åœæ­¢å“åº”è¶…è¿‡ 1 åˆ†é’Ÿ'

      # é«˜é”™è¯¯ç‡å‘Šè­¦
      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: 'é«˜é”™è¯¯ç‡æ£€æµ‹'
          description: '{{ $labels.instance }} 5xx é”™è¯¯ç‡è¶…è¿‡ 10%'

      # å“åº”æ—¶é—´å‘Šè­¦
      - alert: HighResponseTime
        expr:
          histogram_quantile(0.95,
          rate(http_request_duration_seconds_bucket[5m])) > 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: 'å“åº”æ—¶é—´è¿‡é•¿'
          description: '{{ $labels.instance }} 95% å“åº”æ—¶é—´è¶…è¿‡ 1 ç§’'

  - name: infrastructure.rules
    rules:
      # CPU ä½¿ç”¨ç‡å‘Šè­¦
      - alert: HighCPUUsage
        expr:
          100 - (avg by(instance)
          (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: 'CPU ä½¿ç”¨ç‡è¿‡é«˜'
          description: '{{ $labels.instance }} CPU ä½¿ç”¨ç‡è¶…è¿‡ 80%'

      # å†…å­˜ä½¿ç”¨ç‡å‘Šè­¦
      - alert: HighMemoryUsage
        expr:
          (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) *
          100 > 85
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: 'å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜'
          description: '{{ $labels.instance }} å†…å­˜ä½¿ç”¨ç‡è¶…è¿‡ 85%'

      # ç£ç›˜ç©ºé—´å‘Šè­¦
      - alert: DiskSpaceLow
        expr:
          (1 - (node_filesystem_avail_bytes / node_filesystem_size_bytes)) * 100
          > 90
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: 'ç£ç›˜ç©ºé—´ä¸è¶³'
          description: '{{ $labels.instance }} ç£ç›˜ä½¿ç”¨ç‡è¶…è¿‡ 90%'

  - name: database.rules
    rules:
      # æ•°æ®åº“è¿æ¥æ•°å‘Šè­¦
      - alert: HighDatabaseConnections
        expr: pg_stat_database_numbackends > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: 'æ•°æ®åº“è¿æ¥æ•°è¿‡é«˜'
          description: 'PostgreSQL è¿æ¥æ•°è¶…è¿‡ 80'

      # æ•°æ®åº“é”ç­‰å¾…å‘Šè­¦
      - alert: DatabaseLockWait
        expr: pg_locks_count > 10
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: 'æ•°æ®åº“é”ç­‰å¾…'
          description: 'PostgreSQL å­˜åœ¨è¶…è¿‡ 10 ä¸ªé”ç­‰å¾…'
```

### åº”ç”¨ç›‘æ§æŒ‡æ ‡

```typescript
// apps/backend/src/monitoring/metrics.service.ts
import { Injectable } from '@nestjs/common'
import { register, Counter, Histogram, Gauge } from 'prom-client'

@Injectable()
export class MetricsService {
  // HTTP è¯·æ±‚è®¡æ•°å™¨
  private readonly httpRequestsTotal = new Counter({
    name: 'http_requests_total',
    help: 'Total number of HTTP requests',
    labelNames: ['method', 'route', 'status'],
  })

  // HTTP è¯·æ±‚æŒç»­æ—¶é—´
  private readonly httpRequestDuration = new Histogram({
    name: 'http_request_duration_seconds',
    help: 'Duration of HTTP requests in seconds',
    labelNames: ['method', 'route'],
    buckets: [0.1, 0.3, 0.5, 0.7, 1, 3, 5, 7, 10],
  })

  // æ´»è·ƒç”¨æˆ·æ•°
  private readonly activeUsers = new Gauge({
    name: 'active_users_total',
    help: 'Number of active users',
  })

  // æ•°æ®åº“è¿æ¥æ± 
  private readonly dbConnectionsActive = new Gauge({
    name: 'db_connections_active',
    help: 'Number of active database connections',
  })

  // AI API è°ƒç”¨
  private readonly aiApiCalls = new Counter({
    name: 'ai_api_calls_total',
    help: 'Total number of AI API calls',
    labelNames: ['type', 'status'],
  })

  // AI Token ä½¿ç”¨é‡
  private readonly aiTokensUsed = new Counter({
    name: 'ai_tokens_used_total',
    help: 'Total number of AI tokens used',
    labelNames: ['type'],
  })

  constructor() {
    // æ³¨å†Œé»˜è®¤æŒ‡æ ‡
    register.registerMetric(this.httpRequestsTotal)
    register.registerMetric(this.httpRequestDuration)
    register.registerMetric(this.activeUsers)
    register.registerMetric(this.dbConnectionsActive)
    register.registerMetric(this.aiApiCalls)
    register.registerMetric(this.aiTokensUsed)
  }

  // è®°å½• HTTP è¯·æ±‚
  recordHttpRequest(
    method: string,
    route: string,
    status: number,
    duration: number
  ) {
    this.httpRequestsTotal.inc({ method, route, status: status.toString() })
    this.httpRequestDuration.observe({ method, route }, duration)
  }

  // æ›´æ–°æ´»è·ƒç”¨æˆ·æ•°
  setActiveUsers(count: number) {
    this.activeUsers.set(count)
  }

  // æ›´æ–°æ•°æ®åº“è¿æ¥æ•°
  setDbConnections(count: number) {
    this.dbConnectionsActive.set(count)
  }

  // è®°å½• AI API è°ƒç”¨
  recordAiApiCall(type: string, status: 'success' | 'error') {
    this.aiApiCalls.inc({ type, status })
  }

  // è®°å½• AI Token ä½¿ç”¨
  recordAiTokenUsage(type: string, tokens: number) {
    this.aiTokensUsed.inc({ type }, tokens)
  }

  // è·å–æ‰€æœ‰æŒ‡æ ‡
  async getMetrics(): Promise<string> {
    return register.metrics()
  }

  // é‡ç½®æŒ‡æ ‡
  resetMetrics() {
    register.resetMetrics()
  }
}
```

### å¥åº·æ£€æŸ¥ç«¯ç‚¹

```typescript
// apps/backend/src/health/health.controller.ts
import { Controller, Get } from '@nestjs/common'
import { ApiTags, ApiOperation } from '@nestjs/swagger'
import {
  HealthCheckService,
  HealthCheck,
  TypeOrmHealthIndicator,
  MemoryHealthIndicator,
  DiskHealthIndicator,
} from '@nestjs/terminus'
import { PrismaHealthIndicator } from './prisma-health.indicator'
import { RedisHealthIndicator } from './redis-health.indicator'

@ApiTags('health')
@Controller('health')
export class HealthController {
  constructor(
    private health: HealthCheckService,
    private prismaHealth: PrismaHealthIndicator,
    private redisHealth: RedisHealthIndicator,
    private memory: MemoryHealthIndicator,
    private disk: DiskHealthIndicator
  ) {}

  @Get()
  @ApiOperation({ summary: 'å¥åº·æ£€æŸ¥' })
  @HealthCheck()
  check() {
    return this.health.check([
      // æ•°æ®åº“å¥åº·æ£€æŸ¥
      () => this.prismaHealth.isHealthy('database'),

      // Redis å¥åº·æ£€æŸ¥
      () => this.redisHealth.isHealthy('redis'),

      // å†…å­˜ä½¿ç”¨æ£€æŸ¥
      () => this.memory.checkHeap('memory_heap', 150 * 1024 * 1024),
      () => this.memory.checkRSS('memory_rss', 150 * 1024 * 1024),

      // ç£ç›˜ç©ºé—´æ£€æŸ¥
      () =>
        this.disk.checkStorage('storage', {
          path: '/',
          thresholdPercent: 0.9,
        }),
    ])
  }

  @Get('ready')
  @ApiOperation({ summary: 'å°±ç»ªæ£€æŸ¥' })
  @HealthCheck()
  ready() {
    return this.health.check([
      () => this.prismaHealth.isHealthy('database'),
      () => this.redisHealth.isHealthy('redis'),
    ])
  }

  @Get('live')
  @ApiOperation({ summary: 'å­˜æ´»æ£€æŸ¥' })
  live() {
    return {
      status: 'ok',
      timestamp: new Date().toISOString(),
      uptime: process.uptime(),
    }
  }
}
```

## ğŸ”§ è¿ç»´è„šæœ¬

### å¤‡ä»½è„šæœ¬

```bash
#!/bin/bash
# scripts/backup.sh

set -e

# é…ç½®
BACKUP_DIR="/opt/backups/yun-todolist"
DATE=$(date +%Y%m%d_%H%M%S)
RETENTION_DAYS=7

# åˆ›å»ºå¤‡ä»½ç›®å½•
mkdir -p $BACKUP_DIR

echo "ğŸ—„ï¸ å¼€å§‹å¤‡ä»½æ•°æ®åº“..."

# å¤‡ä»½ PostgreSQL
docker exec yun-todolist-postgres pg_dump -U postgres todolist | gzip > $BACKUP_DIR/postgres_$DATE.sql.gz

# å¤‡ä»½ Redis
docker exec yun-todolist-redis redis-cli --rdb /data/dump.rdb
docker cp yun-todolist-redis:/data/dump.rdb $BACKUP_DIR/redis_$DATE.rdb

# å¤‡ä»½åº”ç”¨æ•°æ®
tar -czf $BACKUP_DIR/app_data_$DATE.tar.gz /opt/yun-todolist/data

# å¤‡ä»½é…ç½®æ–‡ä»¶
tar -czf $BACKUP_DIR/config_$DATE.tar.gz /opt/yun-todolist/docker-compose*.yml /opt/yun-todolist/.env*

echo "ğŸ“¦ å¤‡ä»½å®Œæˆï¼Œæ–‡ä»¶ä¿å­˜åœ¨: $BACKUP_DIR"

# æ¸…ç†æ—§å¤‡ä»½
find $BACKUP_DIR -name "*.gz" -mtime +$RETENTION_DAYS -delete
find $BACKUP_DIR -name "*.rdb" -mtime +$RETENTION_DAYS -delete

echo "ğŸ§¹ æ¸…ç† $RETENTION_DAYS å¤©å‰çš„å¤‡ä»½æ–‡ä»¶"

# ä¸Šä¼ åˆ°äº‘å­˜å‚¨ï¼ˆå¯é€‰ï¼‰
if [[ -n "$AWS_S3_BUCKET" ]]; then
    echo "â˜ï¸ ä¸Šä¼ å¤‡ä»½åˆ° S3..."
    aws s3 sync $BACKUP_DIR s3://$AWS_S3_BUCKET/backups/yun-todolist/
fi

echo "âœ… å¤‡ä»½ä»»åŠ¡å®Œæˆ"
```

### æ—¥å¿—è½®è½¬é…ç½®

```bash
# /etc/logrotate.d/yun-todolist
/opt/yun-todolist/logs/*.log {
    daily
    missingok
    rotate 30
    compress
    delaycompress
    notifempty
    create 644 root root
    postrotate
        docker kill -s USR1 yun-todolist-backend 2>/dev/null || true
        docker kill -s USR1 yun-todolist-nginx 2>/dev/null || true
    endscript
}
```

## ğŸ¯ æ ¸å¿ƒå­¦ä¹ è¦ç‚¹

### 1. å®¹å™¨åŒ–æŠ€æœ¯

- **å¤šé˜¶æ®µæ„å»º**ï¼šä¼˜åŒ–é•œåƒå¤§å°å’Œå®‰å…¨æ€§
- **å¥åº·æ£€æŸ¥**ï¼šç¡®ä¿å®¹å™¨æœåŠ¡å¯ç”¨æ€§
- **èµ„æºé™åˆ¶**ï¼šåˆç†åˆ†é… CPU å’Œå†…å­˜
- **ç½‘ç»œéš”ç¦»**ï¼šä½¿ç”¨ Docker ç½‘ç»œè¿›è¡ŒæœåŠ¡éš”ç¦»

### 2. CI/CD æµæ°´çº¿

- **è‡ªåŠ¨åŒ–æµ‹è¯•**ï¼šå•å…ƒæµ‹è¯•ã€é›†æˆæµ‹è¯•ã€å®‰å…¨æ‰«æ
- **å¤šç¯å¢ƒéƒ¨ç½²**ï¼šæµ‹è¯•ã€é¢„ç”Ÿäº§ã€ç”Ÿäº§ç¯å¢ƒ
- **æ»šåŠ¨æ›´æ–°**ï¼šé›¶åœæœºéƒ¨ç½²ç­–ç•¥
- **å›æ»šæœºåˆ¶**ï¼šå¿«é€Ÿæ¢å¤åˆ°ä¸Šä¸€ç‰ˆæœ¬

### 3. ç›‘æ§è§‚æµ‹

- **æŒ‡æ ‡æ”¶é›†**ï¼šPrometheus + Grafana
- **æ—¥å¿—èšåˆ**ï¼šç»“æ„åŒ–æ—¥å¿—å’Œé›†ä¸­æ”¶é›†
- **é“¾è·¯è¿½è¸ª**ï¼šåˆ†å¸ƒå¼ç³»ç»Ÿè°ƒç”¨é“¾åˆ†æ
- **å‘Šè­¦é€šçŸ¥**ï¼šåŠæ—¶å‘ç°å’Œå“åº”é—®é¢˜

### 4. è¿ç»´è‡ªåŠ¨åŒ–

- **åŸºç¡€è®¾æ–½å³ä»£ç **ï¼šDocker Compose é…ç½®ç®¡ç†
- **è‡ªåŠ¨åŒ–å¤‡ä»½**ï¼šæ•°æ®å®‰å…¨ä¿éšœ
- **æ—¥å¿—ç®¡ç†**ï¼šè½®è½¬å’Œå½’æ¡£ç­–ç•¥
- **æ€§èƒ½ä¼˜åŒ–**ï¼šèµ„æºä½¿ç”¨ç›‘æ§å’Œè°ƒä¼˜

## ğŸ“ ç®€å†æŠ€æœ¯äº®ç‚¹

### DevOps æŠ€æœ¯äº®ç‚¹

- **Docker å®¹å™¨åŒ–**ï¼šå¤šé˜¶æ®µæ„å»ºä¼˜åŒ–
- **Kubernetes ç¼–æ’**ï¼šç”Ÿäº§çº§å®¹å™¨ç®¡ç†
- **CI/CD è‡ªåŠ¨åŒ–**ï¼šGitHub Actions æµæ°´çº¿
- **ç›‘æ§å‘Šè­¦ä½“ç³»**ï¼šPrometheus + Grafana

### è¿ç»´æŠ€æœ¯äº®ç‚¹

- **åŸºç¡€è®¾æ–½å³ä»£ç **ï¼šå£°æ˜å¼é…ç½®ç®¡ç†
- **è‡ªåŠ¨åŒ–éƒ¨ç½²**ï¼šé›¶åœæœºæ»šåŠ¨æ›´æ–°
- **å®‰å…¨æ‰«æ**ï¼šä»£ç å’Œé•œåƒå®‰å…¨æ£€æµ‹
- **æ€§èƒ½ç›‘æ§**ï¼šå…¨é“¾è·¯å¯è§‚æµ‹æ€§

### å·¥ç¨‹æŠ€æœ¯äº®ç‚¹

- **é«˜å¯ç”¨æ¶æ„**ï¼šè´Ÿè½½å‡è¡¡å’Œæ•…éšœè½¬ç§»
- **æ•°æ®å¤‡ä»½ç­–ç•¥**ï¼šè‡ªåŠ¨åŒ–å¤‡ä»½å’Œæ¢å¤
- **æ—¥å¿—ç®¡ç†**ï¼šç»“æ„åŒ–æ—¥å¿—å’Œåˆ†æ
- **æˆæœ¬ä¼˜åŒ–**ï¼šèµ„æºä½¿ç”¨æ•ˆç‡æå‡
